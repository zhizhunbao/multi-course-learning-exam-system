# Discussion Topic — The Ethics of Generative Media: Creativity, Ownership, and Authenticity

Generative AI extends human creativity but strains long-standing authorship norms. When artists craft prompts, iterate on outputs, and post-process the result, their agency mirrors a photographer directing a shoot. Model developers contribute the trained system and latent styles, so shared credit—artist as primary author with the AI platform acknowledged—fits moral intuition and emerging policy. These compromises keep creative intent visible while recognizing technological scaffolding. The U.S. Copyright Office has denied registrations for works lacking human control yet accepts filings when people shape the output, signalling that law will hinge on demonstrable human input (U.S. Copyright Office, 2023).

Training data remains the most contested terrain. Scraping portfolios without consent feels like free-riding, even though U.S. fair-use doctrine has tolerated large-scale mining for search engines. Ethical practice should go further: offer opt-outs, share commercial gains, and log provenance. Adobe's Firefly team trained on licensed and public-domain material and watermarks outputs, demonstrating that respectful pipelines are feasible.

Authenticity risks escalate as photorealistic deepfakes proliferate. Synthetic political ads in the 2024 U.S. primaries already spurred state-level disclosure bills. Needed countermeasures include generation-time watermarks, newsroom verification pipelines, and media literacy curricula. Platforms should surface provenance badges, while regulators can require disclosure in high-stakes contexts. UNESCO's 2023 guidance adds appeals and remedies when fabricated media harms individuals (UNESCO, 2023).

For creative professionals, generative tools are double-edged. Game studios already use Midjourney or Stable Diffusion for rapid mood boards, and independent musicians prototype arrangements with Suno. The same efficiency can depress wages and commoditize labor. The 2023 Writers Guild of America strike secured language treating AI outputs as optional tools, underscoring the need for reskilling, updated collective bargaining, and revenue sharing that rewards human editorial labor.

Boundary-setting should be participatory across creators, affected communities, regulators, and technologists. Non-consensual deepfake pornography, deceptive political ads, and synthetic bioweapon designs merit bans or strict licensing. Filters must stay transparent and appealable to avoid overreach. Independent review boards - akin to biomedical ethics committees - and coordination through bodies like the Global Partnership on AI can limit jurisdiction shopping.

Generative media's promise and peril remain intertwined. Centering human agency, respecting consent in datasets, hardening authenticity infrastructure, cushioning creative labor, and co-governing red lines can steer the field toward equitable creativity rather than extractive automation.

## Replies

**Reply to Hye Ran (Word Count: 164)**
Thanks for grounding the discussion in concrete Korean cases. Your point about the MBN virtual anchor reminded me that the Korea Communications Commission recently updated its broadcast review guidelines to require explicit on-air notices when synthetic presenters appear; weaving that in could reinforce your credit argument. I also wonder whether you see potential for collective licensing—similar to how the Korea Music Copyright Association manages rights—to give illustrators and voice actors a pathway for negotiated data use rather than relying solely on opt-outs. On the trust side, it might help to connect the National Election Commission’s rules with the Digital Platform Governance Committee’s push for the C2PA provenance standard, since pairing legal labeling with tamper-evident metadata could close the gap you mentioned between policy and technical enforcement. Finally, given Jeju’s J-na example, do you think local governments should publish impact assessments showing how virtual presenters affect staffing? That transparency might ease labor anxieties while keeping experimentation alive.

**Reply to Authorship & Ownership Post (Word Count: 166)**
I like how you split the debate into concrete buckets—authorship, data, trust, labor, red lines—because it mirrors how regulators are mapping the space. On joint credit, you might nod to the recent U.S. Copyright Office rejection of the Thaler image and the UK Intellectual Property Office’s consultation: both reaffirm that human control remains the threshold, which supports your call for updated statutes while clarifying that model builders are rarely co-authors under today’s standards. Your training-data section could benefit from an example of negotiated access, such as the Shutterstock–OpenAI licensing deal or Spawning’s opt-out registry, to show that “consent plus compensation” is already being prototyped. For labeling, consider mentioning provenance tech like C2PA or the EU’s upcoming AI Act Article 52, since those give your proposal legal and technical scaffolding. Finally, when discussing prohibited outputs, you might distinguish between hard bans (deepfake abuse) and risk-managed categories (political persuasion) so policymakers can calibrate responses instead of defaulting to blanket prohibition.

## References

- U.S. Copyright Office. (2023). _Copyright Registration Guidance for Works Containing AI-Generated Material_. https://www.copyright.gov/ai/
- UNESCO. (2023). _Guidance for Generative AI in Education and Research_. https://www.unesco.org/en/articles/guidance-generative-ai-education-and-research
