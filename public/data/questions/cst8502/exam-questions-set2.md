# CST8502 机器学习 - 综合考试题库（第二套）

> **考试说明**：本题库覆盖所有章节内容，包含 25 道选择题、10 道填空题、简答题、1 道混淆矩阵计算题和 1 道决策树计算题。
>
> **总分**：55 分
>
> - 选择题：25 分（每题 1 分）
> - 填空题：10 分（每题 1 分）
> - 简答题：10 分
> - 模型评估计算题（混淆矩阵）：5 分
> - 决策树计算题：5 分

---

## 📝 第一部分：选择题（Multiple Choice Questions）

**说明**：每题 1 分，共 25 分。选择最佳答案。

### 第 1 题

**来源：第 1 章 - 机器学习导论**

下列哪种任务属于回归问题？

- A. 图像分类
- B. 垃圾邮件识别
- C. 股票价格预测
- D. 客户细分

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：回归问题预测连续数值输出。股票价格预测输出连续的价格值，属于回归问题。其他选项都是分类或聚类问题。

</details>

---

### 第 2 题

**来源：第 1 章 - 机器学习导论**

强化学习的主要特点是什么？

- A. 使用标记数据
- B. 通过奖励和惩罚学习
- C. 发现数据模式
- D. 减少数据维度

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：强化学习通过与环境交互，根据获得的奖励或惩罚来学习最优策略。

</details>

---

### 第 3 题

**来源：第 1 章 - 机器学习导论 & 第 2 章 - 数据预处理**

方差（Variance）的计算公式中，数据点与什么值的差的平方和？

- A. 中位数
- B. 均值
- C. 众数
- D. 最大值

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：方差是数据点与均值之差的平方的平均值，公式为 $\sigma^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i - \mu)^2$。

</details>

---

### 第 4 题

**来源：第 2 章 - 数据预处理与 k-NN**

Z-score 标准化的公式是什么？

- A. (x - min) / (max - min)
- B. (x - mean) / std
- C. x / max
- D. log(x)

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：Z-score 标准化公式为 z = (x - μ) / σ，其中 μ 是均值，σ 是标准差。

</details>

---

### 第 5 题

**来源：第 2 章 - 数据预处理与 k-NN**

在 k-NN 算法中，k 值过大会导致什么问题？

- A. 过拟合
- B. 欠拟合
- C. 内存溢出
- D. 计算错误

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：k 值过大会使模型过于简单，决策边界过于平滑，导致欠拟合，无法捕捉数据的细节特征。

</details>

---

### 第 6 题

**来源：第 2 章 - 数据预处理与 k-NN**

曼哈顿距离（Manhattan Distance）也被称为什么？

- A. L2 范数
- B. L1 范数
- C. L∞ 范数
- D. 欧几里得距离

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：曼哈顿距离是 L1 范数，计算公式为 $d = \sum_{i=1}^{n}|x_i - y_i|$。欧几里得距离是 L2 范数。

</details>

---

### 第 7 题

**来源：第 3 章 - 分类与决策树**

当决策树节点的熵达到最大值时，该节点的纯度如何？

- A. 最纯
- B. 最不纯
- C. 中等纯度
- D. 无法判断

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：熵最大时（例如二分类中两类样本数相等），节点最不纯。熵为 0 时节点最纯。

</details>

---

### 第 8 题

**来源：第 3 章 - 分类与决策树**

C4.5 算法相比 ID3 算法的主要改进是什么？

- A. 使用基尼不纯度
- B. 使用信息增益率
- C. 支持回归问题
- D. 不需要剪枝

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：C4.5 使用信息增益率（Gain Ratio）代替信息增益，可以减少对取值数目较多的特征的偏好，还支持连续值和缺失值处理。

</details>

---

### 第 9 题

**来源：第 3 章 - 分类与决策树**

基尼不纯度（Gini Impurity）的取值范围是多少？

- A. [0, 1]
- B. [-1, 1]
- C. [0, ∞)
- D. (-∞, +∞)

<details>
<summary>查看答案</summary>

**答案：A**

**解释**：基尼不纯度的范围是 [0, 1]，0 表示完全纯净，值越大表示越不纯。对于二分类，最大值为 0.5。

</details>

---

### 第 10 题

**来源：第 3 章 - 分类与决策树**

后剪枝（Post-pruning）相比预剪枝的主要优势是什么？

- A. 速度更快
- B. 更准确
- C. 更简单
- D. 内存占用少

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：后剪枝在完整树的基础上剪枝，通常比预剪枝更准确，因为它能够看到完整的树结构后再做决策，避免过早停止分裂。

</details>

---

### 第 11 题

**来源：第 5 章 - 异常值检测**

使用 Z 分数法时，通常认为 Z 分数的绝对值超过多少的数据点是异常值？

- A. 1
- B. 2
- C. 3
- D. 5

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：通常认为 |Z| > 3 的数据点为异常值。这意味着该点距离均值超过 3 个标准差，在正态分布中出现的概率约为 0.3%。

</details>

---

### 第 12 题

**来源：第 5 章 - 异常值检测**

IQR 方法中，Q1 代表什么？

- A. 第 10 百分位数
- B. 第 25 百分位数
- C. 第 50 百分位数
- D. 第 75 百分位数

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：Q1 是第一四分位数（第 25 百分位数），Q2 是中位数（第 50 百分位数），Q3 是第三四分位数（第 75 百分位数）。

</details>

---

### 第 13 题

**来源：第 5 章 - 异常值检测**

LOF 算法中，如果一个点的 LOF 值接近 1，说明什么？

- A. 该点是异常值
- B. 该点是正常值
- C. 无法判断
- D. 该点在边界上

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：LOF ≈ 1 表示该点的局部密度与其邻居相似，是正常点。LOF >> 1 表示异常值，LOF < 1 表示密度高于邻居。

</details>

---

### 第 14 题

**来源：第 5 章 - 异常值检测**

隔离森林算法的时间复杂度是多少？

- A. O(n²)
- B. O(n log n)
- C. O(n)
- D. O(log n)

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：隔离森林的平均时间复杂度为 O(n log n)，其中 n 是样本数。这使得它适合大规模数据集的异常检测。

</details>

---

### 第 15 题

**来源：第 5 章 - 异常值检测**

以下哪种异常检测方法不需要假设数据分布？

- A. Z 分数法
- B. Grubbs 检验
- C. 隔离森林
- D. 3σ 原则

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：隔离森林是基于树的方法，不需要假设数据服从特定分布。而 Z 分数法、Grubbs 检验和 3σ 原则都假设数据服从正态分布。

</details>

---

### 第 16 题

**来源：第 6 章 - 聚类与 k-Means 算法**

k-Means 算法属于什么类型的学习？

- A. 监督学习
- B. 无监督学习
- C. 半监督学习
- D. 强化学习

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：k-Means 是无监督学习算法，不需要标记数据，通过数据的内在结构进行聚类。

</details>

---

### 第 17 题

**来源：第 6 章 - 聚类与 k-Means 算法**

轮廓系数接近哪个值时，表示聚类效果最好？

- A. -1
- B. 0
- C. 1
- D. 无穷大

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：轮廓系数范围是 [-1, 1]，接近 1 表示样本距离其他簇很远，聚类效果好；接近 -1 表示可能分配错误；接近 0 表示在簇边界上。

</details>

---

### 第 18 题

**来源：第 6 章 - 聚类与 k-Means 算法**

k-Means++ 相比标准 k-Means 的改进在于？

- A. 使用不同的距离度量
- B. 改进质心初始化策略
- C. 改变迭代停止条件
- D. 自动确定 k 值

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：k-Means++ 通过智能初始化质心（让初始质心尽可能远离彼此），提高了聚类质量和收敛速度。

</details>

---

### 第 19 题

**来源：第 6 章 - 聚类与 k-Means 算法**

以下哪种情况下 k-Means 效果可能不佳？

- A. 簇是球形的
- B. 簇大小相似
- C. 簇形状复杂（非凸）
- D. 簇密度相似

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：k-Means 假设簇是凸形（球形）的，对于形状复杂、非凸的簇（如月牙形、环形），效果不佳。这时应考虑使用 DBSCAN 等算法。

</details>

---

### 第 20 题

**来源：第 6 章 - 聚类与 k-Means 算法**

在肘部法（Elbow Method）中，我们寻找的"肘部"是指什么？

- A. WCSS 最小的点
- B. WCSS 最大的点
- C. WCSS 下降速率显著变缓的点
- D. k 值最大的点

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：肘部是 WCSS 曲线中下降速率明显变缓的拐点，表示增加更多簇对改善聚类效果的贡献变小，该点对应的 k 值通常是较优选择。

</details>

---

### 第 21 题

**来源：第 1 章 - 机器学习导论**

欠拟合（Underfitting）通常是由什么原因造成的？

- A. 模型过于复杂
- B. 模型过于简单
- C. 训练数据太多
- D. 测试数据太少

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：欠拟合是指模型过于简单，无法捕捉数据的基本规律，在训练集和测试集上表现都差。

</details>

---

### 第 22 题

**来源：第 1 章 - 机器学习导论 & 模型评估**

在混淆矩阵中，真正例（True Positive, TP）是指什么？

- A. 预测为正例，实际为正例
- B. 预测为正例，实际为负例
- C. 预测为负例，实际为正例
- D. 预测为负例，实际为负例

<details>
<summary>查看答案</summary>

**答案：A**

**解释**：真正例（TP）是指模型预测为正例，实际也是正例的样本数。这是正确分类的正例。

**混淆矩阵四个指标**：

- TP（True Positive）：预测正，实际正 ✓
- FP（False Positive）：预测正，实际负 ✗（第一类错误）
- FN（False Negative）：预测负，实际正 ✗（第二类错误）
- TN（True Negative）：预测负，实际负 ✓

</details>

---

### 第 23 题

**来源：第 1 章 - 机器学习导论 & 模型评估**

准确率（Accuracy）的计算公式是什么？

- A. TP / (TP + FP)
- B. TP / (TP + FN)
- C. (TP + TN) / (TP + TN + FP + FN)
- D. 2TP / (2TP + FP + FN)

<details>
<summary>查看答案</summary>

**答案：C**

**解释**：准确率 = (TP + TN) / 总样本数 = (TP + TN) / (TP + TN + FP + FN)，表示所有正确预测的比例。

**其他评估指标**：

- A. 精确率（Precision）= TP / (TP + FP)
- B. 召回率（Recall/Sensitivity）= TP / (TP + FN)
- D. F1 分数（F1-Score）= 2TP / (2TP + FP + FN)

</details>

---

### 第 24 题

**来源：第 1 章 - 机器学习导论 & 模型评估**

精确率（Precision）和召回率（Recall）哪个更关注"找到的正例中有多少是真的"？

- A. 精确率关注这个问题
- B. 召回率关注这个问题
- C. 两者都关注
- D. 两者都不关注

<details>
<summary>查看答案</summary>

**答案：A**

**解释**：

- **精确率（Precision）**= TP / (TP + FP)，关注"找到的正例中有多少是真的"（查准率）
- **召回率（Recall）**= TP / (TP + FN)，关注"真正例中有多少被找到了"（查全率）

**记忆技巧**：

- Precision（精确）→ 找到的有多准
- Recall（召回）→ 真的找回了多少

**应用场景**：

- 垃圾邮件检测：更关注精确率（避免误判正常邮件）
- 癌症检测：更关注召回率（不能漏掉真正的癌症病例）

</details>

---

### 第 25 题

**来源：第 2 章 - 数据预处理与 k-NN**

在高维空间中，距离度量失效的现象称为什么？

- A. 维度爆炸
- B. 维度诅咒
- C. 维度灾难
- D. 维度陷阱

<details>
<summary>查看答案</summary>

**答案：B**

**解释**：维度诅咒（Curse of Dimensionality）指在高维空间中，数据变得稀疏，所有点之间的距离趋于相似，导致距离度量失效。

</details>

---

## 📝 第二部分：填空题（One-Word Questions）

**说明**：每题 1 分，共 10 分。用一个词或简短短语填空。

### 第 26 题

**来源：第 1 章 - 机器学习导论 & 模型评估**

F1 分数是 \*\*\*\*\_\_\*\*\*\* 和 \*\*\*\*\_\_\*\*\*\* 的调和平均数。

<details>
<summary>查看答案</summary>

**答案**：精确率（Precision）和 召回率（Recall）

**解释**：F1 = 2 × (Precision × Recall) / (Precision + Recall) = 2TP / (2TP + FP + FN)

</details>

---

### 第 27 题

**来源：第 1 章 - 机器学习导论**

在机器学习中，不使用标记数据的学习方式称为 \*\*\*\*\_\_\*\*\*\* 学习。

<details>
<summary>查看答案</summary>

**答案**：无监督（Unsupervised）

</details>

---

### 第 28 题

**来源：第 2 章 - 数据预处理与 k-NN**

k-NN 算法在预测时不需要训练过程，这种学习方式被称为 \*\*\*\*\_\_\*\*\*\* 学习。

<details>
<summary>查看答案</summary>

**答案**：懒惰（Lazy）或 惰性

</details>

---

### 第 29 题

**来源：第 3 章 - 分类与决策树**

决策树中，叶节点代表 \*\*\*\*\_\_\*\*\*\* 或预测值。

<details>
<summary>查看答案</summary>

**答案**：类别（class）或 分类结果

</details>

---

### 第 30 题

**来源：第 3 章 - 分类与决策树**

信息增益等于划分前的熵减去划分后的 \*\*\*\*\_\_\*\*\*\* 熵。

<details>
<summary>查看答案</summary>

**答案**：加权平均（weighted average）或 条件

</details>

---

### 第 31 题

**来源：第 5 章 - 异常值检测**

Z 分数表示数据点距离均值有多少个 \*\*\*\*\_\_\*\*\*\*。

<details>
<summary>查看答案</summary>

**答案**：标准差（standard deviation）

</details>

---

### 第 32 题

**来源：第 5 章 - 异常值检测**

在 IQR 方法中，Q2 也称为 \*\*\*\*\_\_\*\*\*\*。

<details>
<summary>查看答案</summary>

**答案**：中位数（median）

</details>

---

### 第 33 题

**来源：第 5 章 - 异常值检测**

LOF 的全称是 Local \*\*\*\*\_\_\*\*\*\* Factor。

<details>
<summary>查看答案</summary>

**答案**：Outlier

</details>

---

### 第 34 题

**来源：第 6 章 - 聚类与 k-Means 算法**

k-Means 算法的 "k" 代表 \*\*\*\*\_\_\*\*\*\* 的数量。

<details>
<summary>查看答案</summary>

**答案**：簇（cluster）或 类

</details>

---

### 第 35 题

**来源：第 6 章 - 聚类与 k-Means 算法**

轮廓系数（Silhouette Score）同时考虑了簇内 \*\*\*\*\_\_\*\*\*\* 和簇间 \*\*\*\*\_\_\*\*\*\*。

<details>
<summary>查看答案</summary>

**答案**：凝聚度（cohesion）和 分离度（separation）
或：紧密度 和 分离度

</details>

---

## 📝 第三部分：简答题（Short Answer Questions）

**说明**：共 10 分。请简明扼要地回答以下问题。

### 第 36 题（3 分）

**来源：第 1 章 - 机器学习导论**

什么是训练集、验证集和测试集？它们各自的作用是什么？

<details>
<summary>查看参考答案</summary>

**参考答案**：

**三种数据集的定义**（1.5 分）：

- **训练集（Training Set）**：用于训练模型，让模型学习数据的模式和规律
- **验证集（Validation Set）**：用于调整模型的超参数和进行模型选择
- **测试集（Test Set）**：用于评估最终模型的泛化性能

**各自的作用**（1.5 分）：

- 训练集：提供学习样本，用于拟合模型参数
- 验证集：帮助选择最佳模型和超参数，防止过拟合
- 测试集：提供模型性能的无偏估计，评估实际应用效果

**典型划分比例**（额外说明）：60%-70% 训练集，10%-20% 验证集，10%-20% 测试集

**评分要点**：

- 正确说明三种数据集的定义（1.5 分）
- 正确说明它们的作用（1.5 分）
</details>

---

### 第 37 题（4 分）

**来源：第 2 章 - 数据预处理与 k-NN**

比较归一化（Min-Max Normalization）和标准化（Z-score Standardization）的区别，以及它们各自的适用场景。

<details>
<summary>查看参考答案</summary>

**参考答案**：

**主要区别**（2 分）：

- **归一化**：

  - 公式：$x' = \frac{x - min}{max - min}$
  - 将数据缩放到 [0, 1] 范围
  - 受异常值影响大
  - 保持原始数据分布形状

- **标准化**：
  - 公式：$z = \frac{x - \mu}{\sigma}$
  - 将数据转换为均值为 0、标准差为 1
  - 对异常值相对不敏感
  - 数据服从标准正态分布

**适用场景**（2 分）：

- **归一化适用于**：

  - 数据有明确的上下界
  - 神经网络（激活函数如 sigmoid）
  - 图像处理（像素值 0-255）
  - 不包含异常值的数据

- **标准化适用于**：
  - 数据无明确边界
  - 逻辑回归、SVM 等算法
  - 数据包含异常值
  - 需要比较不同特征时

**评分要点**：

- 正确说明两种方法的区别和公式（2 分）
- 正确说明适用场景（2 分）
</details>

---

### 第 38 题（3 分）

**来源：第 3 章 - 分类与决策树**

决策树为什么容易过拟合？列举至少三种防止决策树过拟合的具体方法。

<details>
<summary>查看参考答案</summary>

**参考答案**：

**为什么容易过拟合**（1 分）：
决策树可以无限制地生长，直到完全拟合训练数据，包括噪声和异常值。当树过深或叶节点过多时，会记住训练数据的特殊细节而不是学习一般规律，导致在新数据上表现差。

**防止过拟合的方法**（2 分，每个方法 0.5-0.67 分）：

1. **限制树的深度（max_depth）**：设置最大深度，防止树过深
2. **设置最小分裂样本数（min_samples_split）**：节点样本数少于阈值时不再分裂
3. **设置最小叶节点样本数（min_samples_leaf）**：确保叶节点有足够样本
4. **后剪枝（Post-pruning）**：构建完整树后，剪掉对验证集性能无贡献的分支
5. **限制特征数量（max_features）**：每次分裂只考虑部分特征
6. **集成方法**：使用随机森林、梯度提升树等

**评分要点**：

- 解释为什么容易过拟合（1 分）
- 至少列出 3 种具体方法并简要说明（2 分）
</details>

---

## 📝 第四部分：模型评估计算题（Model Evaluation Math Question）

**说明**：5 分。展示完整的计算过程。

### 第 39 题（5 分）

**来源：第 1 章 - 机器学习导论 & 模型评估**

某医院开发了一个癌症筛查模型，对 100 名患者进行检测，实际结果和模型预测结果如下：

**混淆矩阵**：

|                    | 预测为正例（患癌症） | 预测为负例（未患癌症） |
| ------------------ | -------------------- | ---------------------- |
| 实际正例（患病）   | 35                   | 5                      |
| 实际负例（未患病） | 12                   | 48                     |

**要求**：

1. 计算准确率（Accuracy）（1 分）
2. 计算精确率（Precision）（1 分）
3. 计算召回率（Recall）（1 分）
4. 计算 F1 分数（F1-Score）（1 分）
5. 从医疗应用的角度，分析这个模型的优缺点，应该更关注哪个指标？（1 分）

**公式提示**：

- 准确率：$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$
- 精确率：$Precision = \frac{TP}{TP + FP}$
- 召回率：$Recall = \frac{TP}{TP + FN}$
- F1 分数：$F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$ 或 $F1 = \frac{2TP}{2TP + FP + FN}$

<details>
<summary>查看详细解答</summary>

**完整解答：**

---

**步骤 0：识别混淆矩阵的四个值**

从表格中提取：

- **TP（True Positive，真正例）**= 35（预测患病，实际患病）✓
- **FP（False Positive，假正例）**= 12（预测患病，实际未患病）✗ 第一类错误
- **FN（False Negative，假负例）**= 5（预测未患病，实际患病）✗ 第二类错误
- **TN（True Negative，真负例）**= 48（预测未患病，实际未患病）✓

总样本数 = 35 + 12 + 5 + 48 = 100

---

**步骤 1：计算准确率（Accuracy）**（1 分）

准确率表示所有预测正确的比例：

$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN} = \frac{35 + 48}{100} = \frac{83}{100} = 0.83$$

**准确率 = 83%**

**解释**：模型对 100 个患者中的 83 个做出了正确预测。

---

**步骤 2：计算精确率（Precision）**（1 分）

精确率表示"预测为正例的样本中，有多少是真正的正例"：

$$Precision = \frac{TP}{TP + FP} = \frac{35}{35 + 12} = \frac{35}{47} = 0.745$$

**精确率 = 74.5%**

**解释**：在模型预测为"患癌症"的 47 个患者中，实际有 35 个真的患病，12 个是误诊（假阳性）。

---

**步骤 3：计算召回率（Recall）**（1 分）

召回率表示"实际为正例的样本中，有多少被正确识别"：

$$Recall = \frac{TP}{TP + FN} = \frac{35}{35 + 5} = \frac{35}{40} = 0.875$$

**召回率 = 87.5%**

**解释**：在 40 个真正患癌症的患者中，模型正确识别出了 35 个，遗漏了 5 个（假阴性）。

---

**步骤 4：计算 F1 分数（F1-Score）**（1 分）

F1 分数是精确率和召回率的调和平均数：

方法一（使用精确率和召回率）：
$$F1 = \frac{2 \times Precision \times Recall}{Precision + Recall} = \frac{2 \times 0.745 \times 0.875}{0.745 + 0.875}$$

$$= \frac{1.304}{1.620} = 0.805$$

方法二（直接公式）：
$$F1 = \frac{2TP}{2TP + FP + FN} = \frac{2 \times 35}{70 + 12 + 5} = \frac{70}{87} = 0.805$$

**F1 分数 = 80.5%**

**解释**：F1 分数综合考虑了精确率和召回率，是两者的平衡指标。

---

**步骤 5：医疗应用分析**（1 分）

**模型的优点**：

- 准确率较高（83%），整体预测效果不错
- **召回率很高（87.5%）**，能够识别出大部分真实的患者，只有 5 个漏诊
- F1 分数达到 80.5%，精确率和召回率比较平衡

**模型的缺点**：

- 精确率相对较低（74.5%），有 12 个假阳性（误诊）
- 假阳性会导致不必要的进一步检查，增加患者焦虑和医疗成本

**关键分析**：

在癌症筛查这样的医疗场景中，**应该更关注召回率（Recall）**，原因是：

1. **假阴性（FN）的代价极高**：漏诊癌症患者可能导致延误治疗，危及生命
2. **假阳性（FP）的代价相对较低**：误诊可以通过后续更精确的检查纠正
3. **宁可误诊，不可漏诊**：在初筛阶段，高召回率确保尽可能少的患者被遗漏

**本模型的召回率为 87.5%**，意味着只有 5 个真实患者被漏诊（假阴性），这在初筛阶段是比较好的表现。12 个假阳性可以通过后续的精确检查（如活检）来排除。

**建议**：

- 如果要提高召回率，可以降低阈值，让模型更倾向于预测为正例
- 可以建立两阶段筛查系统：第一阶段高召回率（初筛），第二阶段高精确率（精确诊断）

---

**评分标准**：

- 正确计算准确率（1 分）
- 正确计算精确率（1 分）
- 正确计算召回率（1 分）
- 正确计算 F1 分数（1 分）
- 正确分析医疗场景下应关注召回率（1 分）
  - 说明假阴性代价高（0.5 分）
  - 说明假阳性代价低（0.5 分）
- 部分分：如果公式正确但计算错误，可得 70% 分数

</details>

---

## 📝 第五部分：决策树计算题（Decision Tree Math Question）

**说明**：5 分。展示完整的计算过程。

### 第 40 题（5 分）

**来源：第 3 章 - 分类与决策树**

给定以下贷款审批数据集，使用 ID3 算法（基于信息增益）构建决策树的第一层（只需确定根节点）。

**数据集：**

| 序号 | 年龄 | 收入 | 学历 | 信用 | 批准 |
| ---- | ---- | ---- | ---- | ---- | ---- |
| 1    | 青年 | 高   | 本科 | 好   | 是   |
| 2    | 青年 | 高   | 本科 | 好   | 是   |
| 3    | 中年 | 高   | 本科 | 好   | 是   |
| 4    | 老年 | 中   | 本科 | 好   | 是   |
| 5    | 老年 | 低   | 专科 | 好   | 否   |
| 6    | 老年 | 低   | 专科 | 差   | 否   |
| 7    | 中年 | 低   | 专科 | 差   | 否   |
| 8    | 青年 | 中   | 本科 | 好   | 是   |
| 9    | 青年 | 低   | 专科 | 差   | 否   |
| 10   | 中年 | 中   | 专科 | 好   | 是   |

**要求**：

1. 计算目标变量"批准"的熵 H(批准)（1 分）
2. 计算特征"收入"的信息增益 IG(批准, 收入)（2 分）
3. 计算特征"信用"的信息增益 IG(批准, 信用)（2 分）
4. 确定根节点应该选择哪个特征（不需要计算其他特征）

**公式提示**：

- 熵：$H(S) = -\sum_{i=1}^{c} p_i \log_2(p_i)$
- 信息增益：$IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)$

<details>
<summary>查看详细解答</summary>

**完整解答：**

---

**步骤 1：计算目标变量的熵 H(批准)**（1 分）

统计数据：

- 总样本数：10
- 批准"是"：6 个（样本 1, 2, 3, 4, 8, 10）
- 批准"否"：4 个（样本 5, 6, 7, 9）

计算熵：
$$H(\text{批准}) = -\frac{6}{10}\log_2(\frac{6}{10}) - \frac{4}{10}\log_2(\frac{4}{10})$$

$$= -0.6 \times (-0.737) - 0.4 \times (-1.322)$$

$$= 0.442 + 0.529 = 0.971$$

**H(批准) = 0.971**

---

**步骤 2：计算特征"收入"的信息增益**（2 分）

**统计"收入"特征的分布：**

- **高收入**：3 个样本（1, 2, 3）

  - 是：3 个（1, 2, 3）
  - 否：0 个
  - $H(\text{高}) = 0$（纯净！）

- **中收入**：3 个样本（4, 8, 10）

  - 是：3 个（4, 8, 10）
  - 否：0 个
  - $H(\text{中}) = 0$（纯净！）

- **低收入**：4 个样本（5, 6, 7, 9）
  - 是：0 个
  - 否：4 个（5, 6, 7, 9）
  - $H(\text{低}) = 0$（纯净！）

**计算加权平均熵：**
$$H_{\text{收入}} = \frac{3}{10} \times 0 + \frac{3}{10} \times 0 + \frac{4}{10} \times 0 = 0$$

**计算信息增益：**
$$IG(\text{批准}, \text{收入}) = 0.971 - 0 = 0.971$$

**IG(批准, 收入) = 0.971** ⭐（完美分割！）

---

**步骤 3：计算特征"信用"的信息增益**（2 分）

**统计"信用"特征的分布：**

- **好信用**：7 个样本（1, 2, 3, 4, 5, 8, 10）

  - 是：6 个（1, 2, 3, 4, 8, 10）
  - 否：1 个（5）
  - $H(\text{好}) = -\frac{6}{7}\log_2(\frac{6}{7}) - \frac{1}{7}\log_2(\frac{1}{7})$
  - $= -0.857 \times (-0.222) - 0.143 \times (-2.807)$
  - $= 0.190 + 0.401 = 0.591$

- **差信用**：3 个样本（6, 7, 9）
  - 是：0 个
  - 否：3 个（6, 7, 9）
  - $H(\text{差}) = 0$（纯净！）

**计算加权平均熵：**
$$H_{\text{信用}} = \frac{7}{10} \times 0.591 + \frac{3}{10} \times 0 = 0.414$$

**计算信息增益：**
$$IG(\text{批准}, \text{信用}) = 0.971 - 0.414 = 0.557$$

**IG(批准, 信用) = 0.557**

---

**步骤 4：确定根节点**

比较信息增益：

- **IG(批准, 收入) = 0.971** ⭐⭐⭐（最大！完美分割）
- IG(批准, 信用) = 0.557

**结论：根节点应该选择"收入"特征**，因为它具有最大的信息增益（0.971），能够完美地分割数据集。

**分析**：选择"收入"后，三个子节点（高、中、低）都是纯净的，不需要继续分裂即可完成决策树的构建。

---

**评分标准**：

- 正确计算 H(批准)（1 分）
- 正确计算 IG(批准, 收入)，包括中间步骤（2 分）
  - 正确统计各子集（0.5 分）
  - 正确计算各子集熵（1 分）
  - 正确计算信息增益（0.5 分）
- 正确计算 IG(批准, 信用)，包括中间步骤（2 分）
  - 正确统计各子集（0.5 分）
  - 正确计算各子集熵（1 分）
  - 正确计算信息增益（0.5 分）
- 部分分：如果计算方法正确但算术错误，可得 80% 分数

</details>

---

## 🎓 考试结束

**总分：55 分**

- 选择题（1-25）：25 分
- 填空题（26-35）：10 分
- 简答题（36-38）：10 分
- 模型评估计算题（39）：5 分
- 决策树计算题（40）：5 分

---

## 📊 评分标准

### A 级（50-55 分）

- 优秀掌握所有核心概念
- 能够正确应用算法
- 计算题步骤完整，结果准确
- 深入理解模型评估指标的应用场景

### B 级（44-49 分）

- 良好掌握大部分概念
- 基本能够应用算法
- 计算题方法正确，可能有小错误

### C 级（38-43 分）

- 掌握基本概念
- 能够部分应用算法
- 计算题理解基本方法

### D 级（33-37 分）

- 了解部分基本概念
- 应用能力较弱
- 计算题有明显困难

### F 级（<33 分）

- 基本概念不清楚
- 无法应用算法
- 计算题无法完成

---

## 📚 复习建议

### 重点复习内容

1. **第 1 章：机器学习导论 & 模型评估**

   - 三大学习类型的定义和应用
   - 训练集、验证集、测试集的作用
   - 过拟合和欠拟合的识别与解决
   - **混淆矩阵及评估指标**（新增重点！）
     - TP、FP、FN、TN 的含义
     - 准确率、精确率、召回率、F1 分数的计算
     - 不同应用场景下指标的选择（医疗、垃圾邮件等）

2. **第 2 章：数据预处理与 k-NN**

   - 归一化和标准化的区别
   - k-NN 算法的优缺点
   - 距离度量方法的选择

3. **第 3 章：决策树**

   - 熵和信息增益的手工计算（重点！）
   - 不同决策树算法的特点
   - 防止过拟合的方法

4. **第 5 章：异常值检测**

   - 各种检测方法的原理和适用场景
   - 基于统计 vs 基于密度的方法
   - 异常值的处理策略

5. **第 6 章：聚类**
   - k-Means 算法的完整流程
   - 聚类评估指标的计算和解释
   - k 值的选择方法

### 练习建议

- **重点练习混淆矩阵计算题**（新增！），理解四个基本指标和四个评估指标
- 多做决策树的手工计算，熟练掌握信息增益的计算流程
- 对比不同算法的优缺点和适用场景
- 理解评估指标的含义，能够根据指标判断模型性能
- 练习数据预处理的实际操作
- 理解不同应用场景下应该关注哪个评估指标（医疗、推荐系统、垃圾邮件等）

---

**祝考试顺利！Good Luck! 🍀**
